{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lab work ‚Ññ1.2\n",
    "\n",
    "Student name - Khrystyna\n",
    "\n",
    "Student surname - Zyryanova\n",
    "\n",
    "Group - CS-32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–†–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å –¥–∞–Ω–∏—Ö: (20640, 9)\n",
      "–ü–µ—Ä—à—ñ 5 —Ä—è–¥–∫—ñ–≤ –¥–∞–Ω–∏—Ö:\n",
      "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
      "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
      "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
      "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
      "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
      "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
      "\n",
      "   Longitude  MedHouseVal  \n",
      "0    -122.23        4.526  \n",
      "1    -122.22        3.585  \n",
      "2    -122.24        3.521  \n",
      "3    -122.25        3.413  \n",
      "4    -122.25        3.422  \n",
      "\n",
      "–†–æ–∑–º—ñ—Ä —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω–æ–≥–æ –Ω–∞–±–æ—Ä—É: (16512, 8)\n",
      "\n",
      "–ú–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è –∑–∞–≤–µ—Ä—à–µ–Ω–æ.\n",
      "–°–µ—Ä–µ–¥–Ω—î –∑–Ω–∞—á–µ–Ω–Ω—è MedInc –ø—ñ—Å–ª—è –º–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è (–º–∞—î –±—É—Ç–∏ –±–ª–∏–∑—å–∫–µ –¥–æ 0): 0.0000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "STUDENT_NO = 11\n",
    "\n",
    "# 1. –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞—Ç–∞—Å–µ—Ç—É California Housing\n",
    "housing = fetch_california_housing(as_frame=True)\n",
    "df = housing.frame\n",
    "X = df.drop('MedHouseVal', axis=1) # –û–∑–Ω–∞–∫–∏ (Features)\n",
    "y = df['MedHouseVal']              # –¶—ñ–ª—å–æ–≤–∞ –∑–º—ñ–Ω–Ω–∞ (Target)\n",
    "\n",
    "print(f\"–†–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å –¥–∞–Ω–∏—Ö: {df.shape}\")\n",
    "print(f\"–ü–µ—Ä—à—ñ 5 —Ä—è–¥–∫—ñ–≤ –¥–∞–Ω–∏—Ö:\")\n",
    "print(df.head())\n",
    "\n",
    "# 2. –†–æ–∑–¥—ñ–ª–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö –Ω–∞ —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω–∏–π —Ç–∞ —Ç–µ—Å—Ç–æ–≤–∏–π –Ω–∞–±–æ—Ä–∏\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=STUDENT_NO\n",
    ")\n",
    "\n",
    "print(f\"\\n–†–æ–∑–º—ñ—Ä —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω–æ–≥–æ –Ω–∞–±–æ—Ä—É: {X_train.shape}\")\n",
    "\n",
    "# 3. –ú–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è –¥–∞–Ω–∏—Ö\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# –ü–µ—Ä–µ—Ç–≤–æ—Ä–µ–Ω–Ω—è –Ω–∞–∑–∞–¥ —É DataFrame\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "\n",
    "print(\"\\n–ú–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è –∑–∞–≤–µ—Ä—à–µ–Ω–æ.\")\n",
    "print(f\"–°–µ—Ä–µ–¥–Ω—î –∑–Ω–∞—á–µ–Ω–Ω—è MedInc –ø—ñ—Å–ª—è –º–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è (–º–∞—î –±—É—Ç–∏ –±–ª–∏–∑—å–∫–µ –¥–æ 0): {X_train_scaled_df['MedInc'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ –ó–∞–ø—É—Å–∫ GridSearchCV –¥–ª—è RandomForestRegressor...\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "\n",
      "--- ‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è RFR ---\n",
      "–ù–∞–π–∫—Ä–∞—â—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏: {'max_depth': 25, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "–ù–∞–π–∫—Ä–∞—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç (Negative MSE): -0.2669\n"
     ]
    }
   ],
   "source": [
    "param_grid_rfr = {\n",
    "    'n_estimators': [50, 100], \n",
    "    'max_depth': [15, 25],   \n",
    "    'min_samples_split': [5, 10]\n",
    "}\n",
    "rfr = RandomForestRegressor(random_state=STUDENT_NO)\n",
    "grid_search_rfr = GridSearchCV(estimator=rfr, param_grid=param_grid_rfr, scoring='neg_mean_squared_error', cv=3, n_jobs=-1, verbose=1)\n",
    "\n",
    "print(\"–ó–∞–ø—É—Å–∫ GridSearchCV –¥–ª—è RandomForestRegressor...\")\n",
    "grid_search_rfr.fit(X_train_scaled_df, y_train)\n",
    "\n",
    "best_rfr = grid_search_rfr.best_estimator_\n",
    "print(\"\\n--- –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è RFR ---\")\n",
    "print(f\"–ù–∞–π–∫—Ä–∞—â—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏: {grid_search_rfr.best_params_}\")\n",
    "print(f\"–ù–∞–π–∫—Ä–∞—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç (Negative MSE): {grid_search_rfr.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " –ó–∞–ø—É—Å–∫ GridSearchCV –¥–ª—è GradientBoostingRegressor...\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "\n",
      "--- –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è GBR ---\n",
      "–ù–∞–π–∫—Ä–∞—â—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 300}\n",
      "–ù–∞–π–∫—Ä–∞—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç (Negative MSE): -0.2244\n"
     ]
    }
   ],
   "source": [
    "param_grid_gbr = {\n",
    "    'n_estimators': [100, 300],\n",
    "    'learning_rate': [0.05, 0.1], \n",
    "    'max_depth': [3, 5]\n",
    "}\n",
    "gbr = GradientBoostingRegressor(random_state=STUDENT_NO)\n",
    "grid_search_gbr = GridSearchCV(estimator=gbr, param_grid=param_grid_gbr, scoring='neg_mean_squared_error', cv=3, n_jobs=-1, verbose=1)\n",
    "\n",
    "print(\"\\n –ó–∞–ø—É—Å–∫ GridSearchCV –¥–ª—è GradientBoostingRegressor...\")\n",
    "grid_search_gbr.fit(X_train_scaled_df, y_train)\n",
    "\n",
    "best_gbr = grid_search_gbr.best_estimator_\n",
    "print(\"\\n--- –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è GBR ---\")\n",
    "print(f\"–ù–∞–π–∫—Ä–∞—â—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏: {grid_search_gbr.best_params_}\")\n",
    "print(f\"–ù–∞–π–∫—Ä–∞—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç (Negative MSE): {grid_search_gbr.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# --- –î–æ–ø–æ–º—ñ–∂–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è (evaluate_regression_model) ---\n",
    "def evaluate_regression_model(y_true, X, model, print_results=True):\n",
    "    if hasattr(model, 'predict'):\n",
    "        y_pred = model.predict(X)\n",
    "    else:\n",
    "        raise TypeError(\"Model type not supported. Please provide a scikit-learn model.\")\n",
    "\n",
    "    metrics = {\n",
    "        'MAE': mean_absolute_error(y_true, y_pred),\n",
    "        'MSE': mean_squared_error(y_true, y_pred),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        'R2': r2_score(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "    if print_results:\n",
    "        print(\"----- Model Evaluation -----\")\n",
    "        print(pd.Series(metrics).to_string(float_format=\"%.4f\"))\n",
    "        print(\"-----------------------------\")\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " –ó–∞–ø—É—Å–∫ GridSearchCV –¥–ª—è SVR...\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "\n",
      "--- –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è SVR ---\n",
      "–ù–∞–π–∫—Ä–∞—â—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏: {'C': 10, 'gamma': 1, 'kernel': 'rbf'}\n",
      "–ù–∞–π–∫—Ä–∞—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç (Negative MSE): -0.3330\n"
     ]
    }
   ],
   "source": [
    "param_grid_svr = {\n",
    "    'C': [1, 10], \n",
    "    'gamma': [0.1, 1], \n",
    "    'kernel': ['rbf'] \n",
    "} \n",
    "svr = SVR()\n",
    "grid_search_svr = GridSearchCV(estimator=svr, param_grid=param_grid_svr, scoring='neg_mean_squared_error', cv=3, n_jobs=-1, verbose=1)\n",
    "\n",
    "print(\"\\n –ó–∞–ø—É—Å–∫ GridSearchCV –¥–ª—è SVR...\")\n",
    "grid_search_svr.fit(X_train_scaled_df, y_train)\n",
    "\n",
    "best_svr = grid_search_svr.best_estimator_\n",
    "print(\"\\n--- –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è SVR ---\")\n",
    "print(f\"–ù–∞–π–∫—Ä–∞—â—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏: {grid_search_svr.best_params_}\")\n",
    "print(f\"–ù–∞–π–∫—Ä–∞—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç (Negative MSE): {grid_search_svr.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== –§—ñ–Ω–∞–ª—å–Ω–µ –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è –Ω–∞ X_test ===\n",
      "\n",
      "--- RandomForestRegressor ---\n",
      "R2 –Ω–∞ —Ç–µ—Å—Ç—ñ: 0.8120\n",
      "RMSE –Ω–∞ —Ç–µ—Å—Ç—ñ: 0.5030\n",
      "\n",
      "--- GradientBoostingRegressor ---\n",
      "R2 –Ω–∞ —Ç–µ—Å—Ç—ñ: 0.8395\n",
      "RMSE –Ω–∞ —Ç–µ—Å—Ç—ñ: 0.4648\n",
      "\n",
      "--- SVR ---\n",
      "R2 –Ω–∞ —Ç–µ—Å—Ç—ñ: 0.7672\n",
      "RMSE –Ω–∞ —Ç–µ—Å—Ç—ñ: 0.5597\n",
      "\n",
      "==============================================\n",
      "–ù–∞–π–∫—Ä–∞—â–∞ –º–æ–¥–µ–ª—å –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º—É –Ω–∞–±–æ—Ä—ñ: GradientBoostingRegressor\n",
      "R2 Score: 0.8395\n",
      "==============================================\n"
     ]
    }
   ],
   "source": [
    "final_models = {\n",
    "    \"RandomForestRegressor\": best_rfr,\n",
    "    \"GradientBoostingRegressor\": best_gbr,\n",
    "    \"SVR\": best_svr\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "print(\"\\n=== –§—ñ–Ω–∞–ª—å–Ω–µ –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è –Ω–∞ X_test ===\")\n",
    "\n",
    "X_test_final = X_test_scaled_df \n",
    "\n",
    "for name, model in final_models.items():\n",
    "    # evaluate_regression_model\n",
    "    metrics = evaluate_regression_model(y_test, X_test_final, model=model, print_results=False)\n",
    "    \n",
    "    print(f\"\\n--- {name} ---\")\n",
    "    print(f\"R2 –Ω–∞ —Ç–µ—Å—Ç—ñ: {metrics['R2']:.4f}\")\n",
    "    print(f\"RMSE –Ω–∞ —Ç–µ—Å—Ç—ñ: {metrics['RMSE']:.4f}\")\n",
    "    \n",
    "    results[name] = metrics\n",
    "\n",
    "# –§—ñ–Ω–∞–ª—å–Ω–µ –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è —Ç–∞ –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è –ø–µ—Ä–µ–º–æ–∂—Ü—è\n",
    "if results:\n",
    "    best_r2 = max(metrics['R2'] for metrics in results.values())\n",
    "    best_model_name = [name for name, metrics in results.items() if metrics['R2'] == best_r2][0]\n",
    "\n",
    "    print(\"\\n==============================================\")\n",
    "    print(f\"–ù–∞–π–∫—Ä–∞—â–∞ –º–æ–¥–µ–ª—å –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º—É –Ω–∞–±–æ—Ä—ñ: {best_model_name}\")\n",
    "    print(f\"R2 Score: {best_r2:.4f}\")\n",
    "    print(\"==============================================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
